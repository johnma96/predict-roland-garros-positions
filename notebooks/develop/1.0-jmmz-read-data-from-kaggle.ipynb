{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this initial code to work in the notebook as if it were a module, that \n",
    "# is, to be able to export classes and functions from other subpackages.\n",
    "\n",
    "import pyprojroot\n",
    "import sys\n",
    "\n",
    "package_path = pyprojroot.here().__str__()\n",
    "if package_path not in sys.path:\n",
    "    sys.path.append(package_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AbsPaths\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_dataset(path, dataset_name):\n",
    "    try:\n",
    "        zip_file = dataset_name+'.zip'\n",
    "        zf = ZipFile(file=path+zip_file)\n",
    "        list_files_zip = zf.namelist()\n",
    "        zf.close()\n",
    "        for filename in [*[path+l for l in list_files_zip], path+zip_file]:\n",
    "            os.remove(filename)\n",
    "    except: pass\n",
    "    \n",
    "\n",
    "def dowload_kaggle_dataset(owner_dataset:str , dataset_name:str , \n",
    "                            path_to_save:str = None, uncompress_dataset = True,\n",
    "                            **kwargs):\n",
    "    \"\"\"\n",
    "    Download a complete dataset or parts of a dataset using the kaggle API. You \n",
    "    need to dowload credentials and put it at ~/.kaggle/kaggle.json on Linux, OSX, \n",
    "    and other UNIX-based operating systems, and at C:\\\\Users<Windows-username>.kaggle\\\\kaggle.json \n",
    "    on Windows To get more information about de API please read \n",
    "    https://www.kaggle.com/docs/api \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    owner_dataset : str\n",
    "        Kaglee user who owns the dataset\n",
    "    dataset_name : str\n",
    "        Name of the dataset to be downloaded\n",
    "    path_to_save : str, optional\n",
    "        Path to save the downloaded .zip file, if None the file is downloaded in \n",
    "        the same path as the executable., by default None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Connect to kaggle api. You need to have kaggle credentials in the path \n",
    "    # 'C:\\Users\\<username>\\.kaggle\\'\n",
    "    \n",
    "    \n",
    "    if path_to_save is None:\n",
    "        path_to_save = AbsPaths().get_abs_path_folder(folder_name='raw')\n",
    "\n",
    "    # Remove .zip file\n",
    "    restart_dataset(path=path_to_save, dataset_name=dataset_name)\n",
    "    \n",
    "    dataset = owner_dataset + '/' + dataset_name\n",
    "\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files(dataset=dataset, path=path_to_save, **kwargs)\n",
    "\n",
    "    if uncompress_dataset:\n",
    "        uncompress_zip_file(file_path=path_to_save+dataset_name+'.zip')\n",
    "\n",
    "\n",
    "def uncompress_zip_file(file_path: str = None):\n",
    "    \"\"\"\n",
    "    Unzip a .zip file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str, optional\n",
    "        Absolute path of the file to be decompressed. If None, a filename must \n",
    "        be supplied that is found within the repository., by default None\n",
    "    file_name : str, optional\n",
    "        File name .zip, by default None\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If no information is provided for unzipping a file\n",
    "    \"\"\"\n",
    "    if (file_path is None):\n",
    "        msg = 'You must provide a file path or file name'\n",
    "        raise FileNotFoundError(msg)\n",
    "    \n",
    "    folder_file = os.sep.join(file_path.split(os.sep)[:-1])\n",
    "    \n",
    "    zf = ZipFile(file=file_path)\n",
    "\n",
    "    # Extracted data is saved in the same directory of the .zip file\n",
    "    zf.extractall(path=folder_file)\n",
    "    zf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_f= AbsPaths().get_abs_path_file('atp-matches-dataset.zip')\n",
    "# zf = ZipFile(file=zip_f)\n",
    "# zf.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h:\\\\My Drive\\\\UN_Analytics_Specialization\\\\data-products\\\\project\\\\predict-roland-garros-positions\\\\data\\\\interim\\\\'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_data = AbsPaths().get_abs_path_folder('interim')\n",
    "interim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_dataset = 'gmadevs'\n",
    "dataset_name = 'atp-matches-dataset'\n",
    "dowload_kaggle_dataset(owner_dataset=owner_dataset, dataset_name=dataset_name)\n",
    "# uncompress_zip_file(file_name='atp-matches-dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncompress_zip_file(file_name='atp-matches-dataset.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dffb378cfcbe0516010cd3d57cbbd990b5eb36e7d2bbd9b040f205f65695b592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
